# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/150msgvrB3hXbnwyOoQwBzhDVIql_1Oe2
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
import imageio
import imutils
import urllib.request
from flask import Flask, flash, request, redirect, url_for, render_template
from werkzeug.utils import secure_filename
from app import app
import os
from PIL import Image as im 

cv2.ocl.setUseOpenCL(False)

feature_extractor = 'orb' # one of 'sift', 'surf', 'brisk', 'orb'
feature_matching = 'bf'

def image_input(train_image,query_image):
  trainImg = imageio.imread('img/'+train_image)
  queryImg = imageio.imread('img/'+query_image)
  trainImg_gray = cv2.cvtColor(trainImg, cv2.COLOR_RGB2GRAY)
  queryImg_gray = cv2.cvtColor(queryImg, cv2.COLOR_RGB2GRAY)
  kpsA, featuresA = detectAndDescribe(trainImg_gray, method=feature_extractor)
  kpsB, featuresB = detectAndDescribe(queryImg_gray, method=feature_extractor)
  fig = plt.figure(figsize=(20,8))

  if feature_matching == 'bf':
      matches = matchKeyPointsBF(featuresA, featuresB, method=feature_extractor)
      img3 = cv2.drawMatches(trainImg,kpsA,queryImg,kpsB,matches[:100],
                            None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)
  elif feature_matching == 'knn':
      matches = matchKeyPointsKNN(featuresA, featuresB, ratio=0.75, method=feature_extractor)
      img3 = cv2.drawMatches(trainImg,kpsA,queryImg,kpsB,np.random.choice(matches,100),
                            None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)
  
  M = getHomography(kpsA, kpsB, featuresA, featuresB, matches, reprojThresh=4)
  if M is None:
    print("Error!")
  (matches, H, status) = M
    
  width = trainImg.shape[1] + queryImg.shape[1]
  height = trainImg.shape[0] + queryImg.shape[0]
  result = cv2.warpPerspective(trainImg, H, (width, height))
  result[0:queryImg.shape[0], 0:queryImg.shape[1]] = queryImg
  gray = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)
  thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)[1]
  cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
  cnts = imutils.grab_contours(cnts)
  c = max(cnts, key=cv2.contourArea)
  (x, y, w, h) = cv2.boundingRect(c)
  result = result[y:y + h, x:x + w]
  # plt.figure(figsize=(20,10))
  # plt.imshow(result)
  data = im.fromarray(result, 'RGB')
  data.save('img/result.png')
  return data

def detectAndDescribe(image, method=None):
    """
    Compute key points and feature descriptors using an specific method
    """
    
    assert method is not None, "You need to define a feature detection method. Values are: 'sift', 'surf'"
    
    # detect and extract features from the image
    if method == 'sift':
        descriptor = cv2.xfeatures2d.SIFT_create()
    elif method == 'surf':
        descriptor = cv2.xfeatures2d.SURF_create()
    elif method == 'brisk':
        descriptor = cv2.BRISK_create()
    elif method == 'orb':
        descriptor = cv2.ORB_create()
        
    # get keypoints and descriptors
    (kps, features) = descriptor.detectAndCompute(image, None)
    
    return (kps, features)

def createMatcher(method,crossCheck):
    "Create and return a Matcher Object"
    
    if method == 'sift' or method == 'surf':
        bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=crossCheck)
    elif method == 'orb' or method == 'brisk':
        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=crossCheck)
    return bf

def matchKeyPointsBF(featuresA, featuresB, method):
    bf = createMatcher(method, crossCheck=True)
        
    # Match descriptors.
    best_matches = bf.match(featuresA,featuresB)
    
    # Sort the features in order of distance.
    # The points with small distance (more similarity) are ordered first in the vector
    rawMatches = sorted(best_matches, key = lambda x:x.distance)
    print("Raw matches (Brute force):", len(rawMatches))
    return rawMatches

def matchKeyPointsKNN(featuresA, featuresB, ratio, method):
    bf = createMatcher(method, crossCheck=False)
    # compute the raw matches and initialize the list of actual matches
    rawMatches = bf.knnMatch(featuresA, featuresB, 2)
    print("Raw matches (knn):", len(rawMatches))
    matches = []

    # loop over the raw matches
    for m,n in rawMatches:
        # ensure the distance is within a certain ratio of each
        # other (i.e. Lowe's ratio test)
        if m.distance < n.distance * ratio:
            matches.append(m)
    return matches

def getHomography(kpsA, kpsB, featuresA, featuresB, matches, reprojThresh):
    # convert the keypoints to numpy arrays
    kpsA = np.float32([kp.pt for kp in kpsA])
    kpsB = np.float32([kp.pt for kp in kpsB])
    
    if len(matches) > 4:

        # construct the two sets of points
        ptsA = np.float32([kpsA[m.queryIdx] for m in matches])
        ptsB = np.float32([kpsB[m.trainIdx] for m in matches])
        
        # estimate the homography between the sets of points
        (H, status) = cv2.findHomography(ptsA, ptsB, cv2.RANSAC,
            reprojThresh)

        return (matches, H, status)
    else:
        return None

# image_input('http://www.ic.unicamp.br/~helio/imagens_registro/foto1A.jpg', 'http://www.ic.unicamp.br/~helio/imagens_registro/foto1B.jpg')




# @app.route('/')
# def form_page():
#   target = os.path.join(app_root, '/img')
#   if not os.path.isdir(target):
#         os.mkdir(target)
#   if request.form:
#     image1 = request.form["img1"]
#     imge2=request.form['img2']
    


    
#     return image_input(image1, imge2)
    

#     return "Successfully Saved"
    

    
#   return render_template('form.html')

@app.route('/')
def upload_form():
  return render_template('upload.html')


@app.route('/', methods=['POST'])
def upload_image():
  if 'file' not in request.files:
    flash('No file part')
    return redirect(request.url)
  file = request.files['file']
  file1=request.files['file1']
  if file.filename == '':
    flash('No image selected for uploading')
    return redirect(request.url)
  if file:
    filename = secure_filename(file.filename)
    file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))
    #print('upload_image filename: ' + filename)
    file_loc=filename
  else:
    flash('Allowed image types are -> png, jpg, jpeg, gif')
    return redirect(request.url)

  if file1.filename == '':
    flash('No image selected for uploading')
    return redirect(request.url)
  if file1:
    filename = secure_filename(file1.filename)
    file1.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))
    #print('upload_image filename: ' + filename)
    
    file1_loc=filename
    flash(file_loc)
    flash(file1_loc)
    image=image_input(file_loc,file1_loc)
    if image:
      
      
      flash('Image successfully uploaded and displayed below')
      return render_template('upload.html', filename='img/result.png')
    else:
      flash("None are able to pair")
      return redirect(request.url)
  else:
    flash('Allowed image types are -> png, jpg, jpeg, gif')
    return redirect(request.url)

# @app.route('/form.html')
# def form():
  
#   img1=request.form["img1"]
#   img2=request.form["img2"]
#   image_form(img1,img2)
  
# @app.route('/images.html', methods=['POST'])
# def image_form(img1,img2):
#   return image_input(img1,img2)








if __name__ == '__main__':
   app.run(debug=True)
